PUT movie_trim_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "trim_analyzer": {
          "tokenizer": "keyword",
          "filter": [
            "lowercase",
            "trim"
          ]
        }
      }
    }
  }
}


{
    "acknowledged": true,
    "shards_acknowledged": true,
    "index": "movie_trim_analyzer"
}



POST movie_trim_analyzer/_analyze
{
   "analyzer": "trim_analyzer",
   "text": "    Harry Potter and the Chamber of Secrets    "
}

{
    "tokens": [
        {
            "token": "harry potter and the chamber of secrets",
            "start_offset": 0,
            "end_offset": 47,
            "type": "word",
            "position": 0
        }
    ]
}
